{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Семинар 1 - Первичный анализ данных, визуализация, etc. \n",
    "\n",
    "__Источник данных:__ [https://opendata.socrata.com/](https://opendata.socrata.com/Government/Airplane-Crashes-and-Fatalities-Since-1908/q2te-8cvq)\n",
    "\n",
    "__Dataset:__ Airplane Crashes and Fatalities Since 1908\n",
    "\n",
    "Содержит полную историю авиакатастроф по всему миру, с 1908 года-по настоящее время.\n",
    "> `../data/Airplane_Crashes_and_Fatalities_Since_1908.csv`\n",
    "\n",
    "## 0. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(palette='deep', style='darkgrid', rc={\"figure.figsize\": (15, 8)})\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Чтение данных и просмотр\n",
    "Воспользуйтесь функцией .read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Airplane_Crashes_and_Fatalities_Since_1908.csv\")\n",
    "\n",
    "\n",
    "#Пока не смотрим на этот код: \n",
    "df['Time'] = df['Time'].str.replace('c:','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- __Date__: Дата инцидента\n",
    "- __Time__: Время инцидента\n",
    "- __Location__: Локация инцидента\n",
    "- __Operator__: Авиакомпания\n",
    "- __Flight #__\n",
    "- __Route__\n",
    "- __Type__: Тип разбившегося самолета \n",
    "- __Registration__:\n",
    "- __cn/In__\n",
    "- __Aborad__: Сколько людей было на борту самолета\n",
    "- __Fatalities__: Число погибших (из тех, кто был на борту)\n",
    "- __Ground:__ Число погибших на земле (из тех, кто не был на борту)\n",
    "- __Summary__: Краткое описание инцидента\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на наш датасет, а так же применим поочередно классы .head(), .tail(), .columns\n",
    "# Ваш Код здесь: \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию Pandas выводит всего 20 столбцов и 60 строк, поэтому если ваш датафрейм больше, воспользуйтесь функцией set_option:\n",
    "> pd.set_option('display.max_columns', 100)  \n",
    "> pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .shape позволяет выводить размер датасета. Можно обращаться к выводу как к масиву с помощью []\n",
    "print(df.shape[0], 'строк')\n",
    "print(df.shape[1], 'столбцов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сформируем таблицу с типами данных с помощью класса .dtypes:\n",
    "df_info = pd.DataFrame(df.dtypes,columns=['Type'])\n",
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим уникальные значения Авиаоператоров с помощью.unique() и их кол-во .nunique() \n",
    "df['Operator'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Бывает удобнее воспользоваться классом .info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Работа с датой\n",
    "Как мы видим колнка Date иммет тип \"object\", хотя pandas умеет работать с типом данных \"datetime64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#смените тип данных для колонки \"Date\" с помощью .to_datetime(), обратите внимание на параметры (dayfirst, yearfirst)\n",
    "#\n",
    "# Ошибки можно проигнорировать параметром errors = 'coerce'\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Time'] = pd.to_datetime(df['Time'], errors = 'coerce')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нам дало изменение типа? В частности теперь мы можем доставать значение года (.dt.year), месяца (.dt.month), дня (.dt.day) и даже дня недели(.dt.dayofweek, Понедельник – 0, Воскресенье – 6)\n",
    "\n",
    "Кстати, чтобы добавить колонку, достаточно просто присвоить значения к df['Название новой колонки']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Достаньте из 'Date' - Год, месяц, день недели. \n",
    "\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "df['day of week'] = df['Date'].dt.dayofweek # Monday = 0, Sunday = 6,\n",
    "\n",
    "df['Hours'] = df['Time'].dt.hour\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обращение к данным, фильтрация и другое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрите сколько инцидентов было в 2002 году: \n",
    "df[df['year'] == 2002].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрите сколько инцидентов было c кол-вом жертв (суммарно на земле и на борту) больше 200: \n",
    "df[df['Fatalities'] + df['Ground'] > 200].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кроме того мы можем производить любые операции со столбцами складывать/умножать/делить/логарифимировать etc.   \n",
    "df['all_victims'] = df['Fatalities'] + df['Ground']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посомтрите сколько инцидентов было c кол-вом жертв (суммарно на земле и на борту) больше 200 в 2002 году: \n",
    "df[(df['year'] == 2002) & (df['all_victims'] > 200)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Где произошел инцидент? Какой был самолет? Сколько было жертв? \n",
    "print('В 2002 году в ', df[(df['year'] == 2002) & (df['all_victims'] > 200)]['Location'].values[0],\n",
    "      'разбился', df[(df['year'] == 2002) & (df['all_victims'] > 200)]['Type'].values[0], '. '\n",
    "      'Общее кол-во жертв', df[(df['year'] == 2002) & (df['all_victims'] > 200)]['all_victims'].values[0]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Самостоятельно прочитать про .loc / .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Работа с текстом и пропусками, объединение таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на столбец 'Location'\n",
    "df['Location'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Как видим локация расписана через запятую, попробуем разбить название с помощью .str.split\n",
    "loc = df['Location'].str.split(',', expand=True)\n",
    "loc.head()\n",
    "\n",
    "#кстати в .str есть много всего полезного, например используемый ранее .replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что у нас появились пропуски, однако чем правее тем более укрупненно можно посмотреть локацию. \n",
    "Пропуски можно удалить с помощью .drop(), однако нам более интересно заполнить их с помощью fillna()\n",
    "Не забывайте, что есть параметр inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc[3] = loc[3].fillna(loc[2])\n",
    "loc[3] = loc[3].fillna(loc[1])\n",
    "loc[3] = loc[3].fillna(loc[0])\n",
    "loc[3].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединим таблицы с помощью pd.merge()\n",
    "df_full = pd.merge(df, loc, left_index=True, right_index=True)\n",
    "df_full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалите колонки '0', '1', '2' с помощью .drop() \n",
    "# переименуйте колонку '3' в  'Country' (по крайней мере мы надеемся, что там страна)\n",
    "df_full = df_full.drop([0,1,2], axis=1)\n",
    "df_full.columns.values[19] = 'Country'\n",
    "df_full.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем признаки: Day_period и Holiday с помощью .apply(lambda x: ...)\n",
    "\n",
    "def get_day_time(hour):\n",
    "    return {\n",
    "          0 <= hour < 6:   'Ночь',\n",
    "          6 <= hour < 11:  'Утро',\n",
    "         11 <= hour < 19:  'День',\n",
    "         19 <= hour < 23:  'Вечер',\n",
    "         23 <= hour < 25:  'Ночь'\n",
    "    }[True]\n",
    "        \n",
    "df_full['Day_period'] = df_full['Hours'].fillna(0).apply(lambda x: get_day_time(x))\n",
    "df_full['Holiday'] = df_full['day of week'].fillna(0).apply(lambda x: 1 if x >= 5 else 0) \n",
    "\n",
    "# .map на самостоятельное изучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сводные таблицы, группировка и агрегация данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C помощью .groupby посчитайте сумму жертв по годам. Затем отсортируйте их по убыванию и сделайте топ-10 \n",
    "df_full.groupby('year').sum().sort_values('all_victims', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нарисуйте график all_victims, Aboard, Fatalities для каждого года\n",
    "df.groupby('year').sum()[['all_victims', 'Ground', 'Fatalities']].plot(rot=45) #kind='bar'\n",
    "plt.title('Количество жерт по годам')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте кол-во Инцидентов и жертв по годам. На этот раз используйте .pivot_table()\n",
    "\n",
    "crashes_by_year = pd.pivot_table(df_full, index='year', values=['Aboard','Fatalities','Ground','all_victims'], aggfunc='sum')\n",
    "crashes_by_year['count'] =  pd.pivot_table(df_full, index='year', values=['all_victims'], aggfunc='count').values.T[0]\n",
    "crashes_by_year.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сколько жертв на инцидент? \n",
    "crashes_by_year['victims_on_incident'] = crashes_by_year['all_victims']/crashes_by_year['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# существует ли корреляция между всеми праметрами? \n",
    "crashes_by_year.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отрисуйте heatmap корреляции для более хорошего визульного представления - используйте sns.heatmap() \n",
    "\n",
    "sns.heatmap(crashes_by_year.corr(), \n",
    "         vmin=-1, vmax=1,annot=True, cmap='RdBu',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бонус! Давайте порисуем еще! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, sharey=True, figsize=(16,6))\n",
    "\n",
    "sns.boxplot(x=\"Day_period\", y=\"Fatalities\", data=df_full[df_full['Fatalities'] < 100],  ax=axes[0]);\n",
    "sns.violinplot(x=\"Day_period\", y=\"Fatalities\", data=df_full[df_full['Fatalities'] < 100], ax=axes[1],\n",
    "              hue='Holiday');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разберём части Boxplot ###\n",
    "\n",
    "__Черта__ – Медиана  \n",
    "__Коробка__ – Интерквартильный размах (IQR или разница 25% (Q1) и 75% (Q3) перцентили)   \n",
    "__Усы__ – Это интервал $\\bigl[ Q_1 - 1.5 \\times IQR$, $Q_3 + 1.5 \\times IQR \\bigr]$  \n",
    "__Точки__ – Выбросы\n",
    "\n",
    "<img src=\"../pic/Boxplot.svg\" width=\"500\">\n",
    "Подообнее на [Wikipedia]('https://en.wikipedia.org/wiki/Box_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22, 5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "sns.distplot(df_full['Fatalities'].dropna(), fit=st.norm, kde=True,ax=ax1, bins=50)\n",
    "ax1.set_title('Плотность распределения переменной')\n",
    "ax2 = fig.add_subplot(122)\n",
    "prob = st.probplot(df_full['Fatalities'].dropna(), dist=st.norm, plot=ax2)\n",
    "ax2.set_title('Probabilyty plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ссылки:\n",
    "- Хороший [обзор основных функций Pandas](https://alexanderdyakonov.files.wordpress.com/2015/04/ama2015_pandas.pdf) от Александра Дьяконова (МГУ)\n",
    "- Открытый курс машинного обучения. [Тема 1. Первичный анализ данных с Pandas](https://habr.com/company/ods/blog/322626/)  \n",
    "- Подробная [Документация Pandas](http://pandas.pydata.org/pandas-docs/stable/api.html)\n",
    "\n",
    "### Литература: \n",
    "- Heydt Michael. Learning Pandas "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
