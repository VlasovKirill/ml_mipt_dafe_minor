{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib\n",
    "#!pip install tqdm\n",
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 6 - Погружение в глубокое обучение\n",
    "В семинаре, будем использовать набор данных `fashion_mnist`, загрузим их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train_cat), (x_test, y_test_cat) = fashion_mnist.load_data()\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "\n",
    "num_classes = 10\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', \n",
    "               'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем случаные примеры для каждого класса и посмотрим на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(y_train_cat[:]==i)[0]\n",
    "    features_idx = x_train[idx,::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    im = features_idx[img_num]\n",
    "    ax.set_title(class_names[i])\n",
    "    plt.imshow(im, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Построим нашу первую нейросеть\n",
    "Импорт `Keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential # Модель, где все слои соединены друг с другом\n",
    "from keras.layers import Dense, Flatten, Activation # Слой, где все нйероны предыдущего уровня соединены с нейронами следующего\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD,Adam,RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проведем небольшие предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train_cat, num_classes=num_classes)\n",
    "y_test = np_utils.to_categorical(y_test_cat, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "# Добавляем слои\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Компилируем модель\n",
    "optimizer = SGD(lr=0.1)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос: \n",
    "Почему: $784 \\times 200 = 156 800$, а сетка показывает число параметров: $157000$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель, задав параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000 # Выбираем размер Батча\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Обучаем модель! \n",
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_history(history):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "viz_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что мы можем улучшить? \n",
    "- Отнормировать признаки\n",
    "- Заменить сигмоиды на ReLu\n",
    "- Задать правила инициации весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормирование\n",
    "<img src='normalize.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отнормируйте и центрируйте признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ваш Код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции активации\n",
    "<img src='activations.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициациия весов\n",
    "__Случайно__  \n",
    "$ w = a * random$, но тогда если $a \\gg 1$, то на выходе $b\\gg1$ и если $a \\ll 1 $, то $b \\approx 0 $  \n",
    "\n",
    "__Xavier__  \n",
    "$a = \\frac{1}{\\sqrt{n}}$, где $n$ - кол-во нейронов на входе\n",
    "\n",
    "__He__  \n",
    "$a = \\frac{1}{\\sqrt{\\frac{n}{2}}}$, где $n$ - кол-во нейронов на входе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import he_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В функции `create_model()` ниже: \n",
    "1. Добавьте инициацию весов в полносвязных слоях с помощью функции `he_normal()`\n",
    "2. Измените функцию активации полносвязных слоев на Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(200))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(lr=0.1)\n",
    "model = create_model(input_shape, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_history(history):\n",
    "    plt.plot(history.history['acc'], label='train')\n",
    "    plt.plot(history.history['val_acc'], label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "viz_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_history(history):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "viz_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Влияние скорости обучения\n",
    "Посмотрим, как влияет параметр `learning_rate` на качество нашей модели на обучающей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебирите значения `[0.001, 0.01, 0.1, 1]` для `learning_rate` и постройте графики зависимости доли правильных ответов (или loss-функции) в зависимости от значения параметра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Влияние метода оптимизации градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='optimizers7.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum\n",
    "Вместо того, чтобы использовать только градиент текущего шага, мы будем накапливать импульс градиента прошлых шагов для определения направления движения. \n",
    "В связи со стохастической природой, обновления градиента происходят \"зигзагообразно\", с помощью момента мы усиливаем движение вдоль основного направления. На практике коэффициент у момента инициализируется на уровне 0,5 и постепенно увеличивается до 0,9 в течение нескольких эпох. \n",
    "  \n",
    "#### Adagrad\n",
    "Некоторые признаки могут быть крайне информативными, но встречаться редко. Экзотическая высокооплачиваемая профессия, причудливое слово в спам-базе — они запросто потонут в шуме всех остальных обновлений. Речь идёт не только о редко встречающихся входных параметрах. Скажем, вам вполне могут встретиться редкие графические узоры, которые и в признак-то превращаются только после прохождения через несколько слоёв свёрточной сети. Хорошо бы уметь обновлять параметры с оглядкой на то, насколько типичный признак они фиксируют. Достичь этого несложно: давайте будем хранить для каждого параметра сети сумму квадратов его обновлений. \n",
    " \n",
    "#### RMSProp (Root Mean Square Propogation)   \n",
    "Мы обновляем меньше веса, которые слишком часто обновляются (идея Adagrad), при этом используем полную суммы обновлений, и используем усреднённый по истории квадрат градиента.\n",
    "\n",
    "#### Adam (Adaptive moment estimation)\n",
    "Cочетает в себе и идею накопления движения и идею более слабого обновления весов для типичных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['SGD with Momentum', 'Adam', 'RMSprop']\n",
    "optimizers = {'SGD with Momentum': SGD(nesterov=True), \n",
    "              'Adam': Adam(),\n",
    "              'RMSprop': RMSprop()\n",
    "             }\n",
    "\n",
    "for opt in tqdm(names):\n",
    "    model = create_model(input_shape, optimizers[opt])\n",
    "    history = model.fit(x_train, y_train, verbose=0,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    plt.plot(history.history['val_acc'], label='optimizers = {}'.format(opt))\n",
    "    \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применим, все полученные знания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam()\n",
    "model = create_model(input_shape, optimizer)\n",
    "\n",
    "history = model.fit(x_train, y_train, verbose=1,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объявляем, борьбу с переобучением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте в сеть слои `Dropout` или `BatchNormalization` после `Dense`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, verbose=1,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теперь твоя очередь! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Побей бейзлайн 2 в соревновании [Птица или самолет](https://www.kaggle.com/c/bird-or-aircraft-dafe-open/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки\n",
    "- [Курс \"Deep learning на пальцах\", лекция 4](https://youtu.be/tnrbx7V9RbA)\n",
    "- [Статья: Оптимизация градиентного спуска](http://ruder.io/optimizing-gradient-descent/)\n",
    "- [Статья: Методы оптимизации нейронных сетей](https://habr.com/ru/post/318970/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
