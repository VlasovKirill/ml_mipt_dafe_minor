{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №4 - Линейные модели - Часть 1\n",
    "\n",
    "Заполните ответы в [форму](https://docs.google.com/forms/d/e/1FAIpQLSe5SEqn2yiQtKlTHkrifwTgWRH8asbCzCkL_uRl70vHxl46Ng/viewform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(palette='deep', style='darkgrid', rc={\"figure.figsize\": (15, 4)})\n",
    "import scipy.stats as st\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейные модели отлично (и лучше) подходят для работы данным в которых очень много признаков, обычно они могут представлять из себя достаточно разряженные признаки.\n",
    "Поэтому воспользуемся датасетом [fetch_20newsgroups](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном датасете 20 типов новостей, однако мы будем решать задачу бинарной классификации и поэтому выберем только две категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_categories = ['alt.atheism', 'sci.space'] # Очень разные категории \n",
    "hard_categories = ['rec.sport.baseball', 'rec.sport.hockey'] # Очень близкие категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_groups_data = fetch_20newsgroups(subset='all', \n",
    "                                     categories=easy_categories,\n",
    "                                     remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим датасет на тестовую и валидационную выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(two_groups_data.data, \n",
    "                                                    two_groups_data.target, \n",
    "                                                    test_size=0.30, random_state=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим примеры текстов из разных категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 832\n",
    "print('Текст из категории ', easy_categories[y_train[n]], ':')\n",
    "print('='*50)\n",
    "print(x_train[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 124\n",
    "print('Текст из категории ', easy_categories[y_train[n]], ':')\n",
    "print('='*50)\n",
    "print(x_train[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с текстами, в машинном обучению применяется метод Мешка слов. Обязательно прочитайте про методы векторизации текста например [здесь](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим параметры для CountVectorizer. Определим Максимальное колличество признаков равным 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = CountVectorizer(max_features=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим векторайзер, учитывайте, что для метода существуют не только фунции .fit и .transform, но и .fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectorized = # Ваш код здесь\n",
    "x_test_vectorized = # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию с параметрами по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Задание 1:__ Чему равны accuracy score и roc auc score на тестовой выборке?   \n",
    "> Будьте внимательны, что для вычисления roc_auc Вам нужно использовать .predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одно из Важных свойст линейных моделей - интерпретируемость результатов. Пожалуйста, изучите подробно этот [материал]('https://www.unm.edu/~schrader/biostat/bio2/Spr06/lec11.pdf')\n",
    "\n",
    "__ Задание 2:__ Отсортируйте в порядке уменьшения важности, признаки для категории новостей \"Космос\"\n",
    "\n",
    "Но мы будем строить график важности для обоих признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame('Ваш код здесь', index='Ваш код здесь',\n",
    "                        columns=['feature importance']\n",
    "                                          ).sort_values(by='feature importance', ascending=False)\n",
    "feat_imp = pd.concat([feat_imp.head(20), feat_imp.tail(20)])\n",
    "\n",
    "colors = [\"red\" if c < 0 else \"blue\" for c in feat_imp.values]\n",
    "\n",
    "plt.bar(feat_imp.index, feat_imp['feature importance'], align='center', color=colors)\n",
    "plt.xticks(feat_imp.index, rotation=90)\n",
    "plt.ylabel('Feature importance')\n",
    "plt.title('Важность признаков')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кривые обучения и Валидации\n",
    "\n",
    "При обучении моделей, очень Важно строить кривые обучения и валидации, они помогают определить:\n",
    "1. Достаточно ли нам данных? \n",
    "2. Существует ли Тендеция к переобучению? \n",
    "3. Наблюдается ли недообучение? \n",
    "\n",
    "Подробнее [Открытый курс Машинного обучения: Тема 5](https://habrahabr.ru/company/ods/blog/323890/#5-krivye-validacii-i-obucheniya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve(acc_train, acc_test):\n",
    "    plt.plot(acc_train, label='train')\n",
    "    plt.plot(acc_test, label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = []\n",
    "acc_train = []\n",
    "\n",
    "sgd = SGDClassifier(loss='hinge', alpha=0.1, max_iter=100, random_state=18)\n",
    "\n",
    "shapes = 50\n",
    "for i in range(120):\n",
    "    shapes = shapes+10\n",
    "    sgd.fit(x_train_vectorized[:shapes], y_train[:shapes] )\n",
    "    acc_train = np.append(acc_train, accuracy_score(y_train[:shapes], sgd.predict(x_train_vectorized)[:shapes]))    \n",
    "    acc_test = np.append(acc_test, accuracy_score(y_test, sgd.predict(x_test_vectorized)))\n",
    "\n",
    "curve(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = []\n",
    "acc_train = []\n",
    "\n",
    "c = np.linspace(1e-18, 10)\n",
    "\n",
    "for i in c:\n",
    "    sgd = SGDClassifier(loss='hinge', alpha=i, max_iter=100, random_state=18)\n",
    "    sgd.fit(x_train_vectorized, y_train)\n",
    "    acc_train = np.append(acc_train, accuracy_score(y_train, sgd.predict(x_train_vectorized)))    \n",
    "    acc_test = np.append(acc_test, accuracy_score(y_test, sgd.predict(x_test_vectorized)))\n",
    "    \n",
    "curve(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3__: Можно ли однозначно сказать, что данных достаточно? (При этих параметрах)  \n",
    "__Задание 4__: Наблюдается ли переобучение?  (При этих параметрах)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте посмотреть как будут меяться кривые обучения и валидации при различных параметрах.\n",
    "Попробуйте так же применить все те же манипуляции к выборке навастей со сложными (близкими категориями)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2: Решение Многоклассовой задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_groups_data = fetch_20newsgroups(subset='all', \n",
    "                                     remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(two_groups_data.data, \n",
    "                                                    two_groups_data.target, \n",
    "                                                    test_size=0.30, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = CountVectorizer(max_features=20000)\n",
    "x_train_vectorized = CV.fit_transform(x_train)\n",
    "x_test_vectorized = CV.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(alpha=1e-20, n_jobs=-1, random_state=124)\n",
    "sgd.fit(x_train_vectorized, y_train) \n",
    "accuracy_score(y_test, sgd.predict(x_test_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас есть Baseline - 0.61231.   \n",
    "\n",
    "__Ваша задача:__\n",
    "1. Добиться Увеличения бейзлайна любыми известными вам способами (но см. условия)\n",
    "2. Загрузить в форму Ваш ноутбук с решением\n",
    "\n",
    "В зависимости от итоговой метрики, договоримся как распределим баллы.  \n",
    "\n",
    "Условия:\n",
    "- Чтобы было честно, нейронки пока не используем\n",
    "- Должна быть воспроизводимость результатов. Не забывайте фиксировать random seed, если воспроизводимости не будет, то результатом будет то значение метрики, которое получилось у меня при воспроизведении Вашего ноутбука. \n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
